{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook produces analysis for outputs from Ocean Plastic Assimilator v0.1\n",
    "# To run, you will need to install the outputs available at http://doi.org/10.5281/zenodo.4426130\n",
    "# and install them in an output/ folder at the roor of this repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve forecast output folders\n",
    "import os\n",
    "\n",
    "def is_output_folder(folder_name: str) -> bool:\n",
    "    return folder_name.find(\"output_double_gyre_\") != -1\n",
    "\n",
    "folders = []\n",
    "for f in os.listdir(\"../outputs/\"):\n",
    "    if is_output_folder(f):\n",
    "        folders.append(\"../outputs/\" + f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "\n",
    "MAX_ITER_COUNT = 4500\n",
    "\n",
    "def parseIntTupleList(l: str) -> List[Tuple[float]]:\n",
    "    content = l.split('[')[1].split(']')[0]\n",
    "    elements = content.split(', ')\n",
    "    result = []\n",
    "    for i in range(0, len(elements), 2):\n",
    "        x = int(elements[i][1:])\n",
    "        y = int(elements[i+1][:-1])\n",
    "        result.append((x,y))\n",
    "\n",
    "    return result\n",
    "\n",
    "def retrieveNumValueFromFolderName(f: str, field: str):\n",
    "    try:\n",
    "        pair = f.split(field)\n",
    "        val = pair[1].split('_')[0 if field == 'v' else 1]\n",
    "        return float(val)\n",
    "    except ValueError:\n",
    "        return parseIntTupleList(val)\n",
    "    except IndexError:\n",
    "        # Default values for fields that were not defined earlier\n",
    "        if field == 'eps':\n",
    "            return 0.25\n",
    "        if field == 'A':\n",
    "            return 0.1\n",
    "        if field == 'nbparts':\n",
    "            return 25000.0\n",
    "        return np.NaN\n",
    "\n",
    "folderNameFields = ['v','as','nbparts','res', 'ens', 'eps', 'rsd', 'A', 'rad', 'devinit', 'meaninit', 'obscov', 'obspoints']\n",
    "out = {k: [] for k in folderNameFields}\n",
    "out['lastWMean'] = []\n",
    "out['lastDErrDev'] = []\n",
    "out['CFRMS'] = []\n",
    "out['nbobspoints'] = []\n",
    "\n",
    "out['iterCount'] = []\n",
    "\n",
    "for f in folders:\n",
    "    for k in folderNameFields:\n",
    "        out[k].append(retrieveNumValueFromFolderName(f, k))\n",
    "    \n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    out['iterCount'].append(n)\n",
    "    out['lastWMean'].append(df_sim['weights_means'][n-1] if df_sim['weights_means'][n-1] != \"--\" else np.nan)\n",
    "    out['lastDErrDev'].append(df_sim['densities_err_stddev'][n-1])\n",
    "    out['nbobspoints'].append(len(retrieveNumValueFromFolderName(f, 'obspoints')))\n",
    "    try:\n",
    "        out['CFRMS'].append(df_sim['CFRMS'][n-1])\n",
    "    except:\n",
    "        out['CFRMS'].append(np.nan)\n",
    "\n",
    "df_lastStats = pd.DataFrame(data=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sim_vars import LONGITUDES, LATITUDES\n",
    "\n",
    "df_lastStats = df_lastStats[~np.isnan(df_lastStats['meaninit'])]\n",
    "df_lastStats['CFRMS'] = df_lastStats['CFRMS'] / np.math.sqrt(LONGITUDES * LATITUDES)\n",
    "#df_lastStats = df_lastStats[df_lastStats['lastDErrMean'] < 100]\n",
    "#df_lastStats = df_lastStats[df_lastStats['rad'] == np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lastStats"
   ]
  },
  {
   "source": [
    "# Generate RMSE without correction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sim_vars import main_dir_path, LONGITUDES, LATITUDES, MIN_LONGITUDE, MIN_LATITUDE, RESOLUTION\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "DS_USEFUL_PATH = f\"{main_dir_path}/parts_double_gyre_forecast_25000_3.nc\"\n",
    "\n",
    "def computeDensitiesLazy(partsLons, partsLats, partsWeights):\n",
    "    d = np.zeros((LONGITUDES, LATITUDES))\n",
    "    for p_id in range(len(partsLons)):\n",
    "        lonId = int(np.floor((partsLons[p_id] - MIN_LONGITUDE) / RESOLUTION))\n",
    "        latId = int(np.floor((partsLats[p_id] - MIN_LATITUDE) / RESOLUTION))\n",
    "        d[min(lonId, LONGITUDES - 1), min(latId, LATITUDES - 1)] += partsWeights[p_id]\n",
    "    return d\n",
    "\n",
    "def generateFileName(epsilon, A):\n",
    "    epsilonStr = str(epsilon).split('.')[0] if str(epsilon)[-1] == '0' else str(epsilon)\n",
    "    return f\"{main_dir_path}parts_double_gyre_ref_eps_{epsilonStr}_A_{A}.nc\"\n",
    "\n",
    "def computeRMSEWithoutCorrection(epsilon, A, muinit):\n",
    "    ds_uncorrected = nc.Dataset(DS_USEFUL_PATH)\n",
    "    ds_ref = nc.Dataset(generateFileName(epsilon, A))\n",
    "    densities_uncorrected = computeDensitiesLazy(ds_uncorrected['lon'][:,-1], ds_uncorrected['lat'][:,-1], ds_uncorrected['weight'][:] * muinit)\n",
    "    densities_ref = computeDensitiesLazy(ds_ref['lon'][:,-1], ds_ref['lat'][:,-1], ds_ref['weight'][:])\n",
    "    diff = densities_uncorrected - densities_ref\n",
    "    RMSE = np.math.sqrt(np.mean(diff ** 2))\n",
    "    print(RMSE)\n",
    "    return RMSE\n",
    "\n",
    "df_lastStats[df_lastStats['v'] == 7.3][df_lastStats['rsd'] == 0][df_lastStats['nbparts'] == 25000].apply(lambda row: computeRMSEWithoutCorrection(row['eps'], row['A'], row['meaninit']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Generate figures"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for f in folders:\n",
    "    name = \"\"\n",
    "    if retrieveNumValueFromFolderName(f, 'rad') != np.inf:\n",
    "        continue\n",
    "    if np.isnan(retrieveNumValueFromFolderName(f, 'meaninit')):\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'obscov') != 0.01:\n",
    "        continue\n",
    "    if len(retrieveNumValueFromFolderName(f, 'obspoints')) != 2:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'ens') != 10:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'nbparts') != 25000:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'v') != 7.3:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'A') != 0.1:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'devinit') != 0.05:\n",
    "        continue\n",
    "    for k in ['eps']:\n",
    "        name += \"$\\epsilon$ = \" + str(retrieveNumValueFromFolderName(f, k))\n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    if (df_sim[\"weights_means\"][:] < 5).all():\n",
    "        out[name] = df_sim[\"weights_means\"]\n",
    "\n",
    "df_convergence_weight_epsilons_means = pd.DataFrame(out)\n",
    "df_convergence_weight_epsilons_means = df_convergence_weight_epsilons_means.reindex(sorted(df_convergence_weight_epsilons_means.columns, reverse=True), axis=1)\n",
    "df_convergence_weight_epsilons_means.insert(0, 'Reference', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Figure 6\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.set_context(\"poster\")\n",
    "ax = sns.lineplot(data=df_convergence_weight_epsilons_means, dashes=True, color=\"0.75\")\n",
    "ax.set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\", ylim=(0,1.5))\n",
    "#ax.set(title=\"Evolution of forecast mass over time for different epsilons \\nLegend: Double gyre epsilon\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for f in folders:\n",
    "    name = \"\"\n",
    "    if retrieveNumValueFromFolderName(f, 'rad') != np.inf:\n",
    "        continue\n",
    "    if np.isnan(retrieveNumValueFromFolderName(f, 'meaninit')):\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'obscov') != 0.01:\n",
    "        continue\n",
    "    if len(retrieveNumValueFromFolderName(f, 'obspoints')) != 2:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'ens') != 10:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'eps') != 0.25:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'meaninit') != 2:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'nbparts') != 25000:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'v') != 7.3:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'devinit') != 0.05:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'A') not in [0.1, 0.105, 0.11, 0.1175, 0.125]:\n",
    "        continue\n",
    "    for k in ['A']:\n",
    "        name += \"$A$ = \" + str(retrieveNumValueFromFolderName(f, k))\n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    if (df_sim[\"weights_means\"][:] < 5).all():\n",
    "        out[name] = df_sim[\"weights_means\"]\n",
    "\n",
    "df_convergence_weight_As_means = pd.DataFrame(out)\n",
    "df_convergence_weight_As_means = df_convergence_weight_As_means.reindex(sorted(df_convergence_weight_As_means.columns), axis=1)\n",
    "df_convergence_weight_As_means.insert(0, 'Reference', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.set_context(\"talk\")\n",
    "ax = sns.lineplot(data=df_convergence_weight_As_means, dashes=True, color=\"0.75\")\n",
    "ax.set(xlabel=\"Iteration count\", ylabel=\"Total mass relative to $M_{ref}$\", ylim=(0,1.5))\n",
    "# ax.set(title=\"Evolution of forecast mass over time for different As \\nLegend: Double gyre A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 1,figsize=(20, 14))\n",
    "sns.set_context(\"talk\")\n",
    "sns.lineplot(data=df_convergence_weight_As_means, dashes=True, color=\"0.75\", ax=axes[1], palette=sns.color_palette(n_colors=6, desat=False))\n",
    "axes[1].set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\")\n",
    "axes[1].set(xscale=\"linear\", ylim=(0,1.5))\n",
    "sns.lineplot(data=df_convergence_weight_epsilons_means, dashes=True, color=\"0.75\", ax=axes[0], palette=sns.color_palette(n_colors=6, desat=False))\n",
    "axes[0].set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\")\n",
    "axes[0].set(xscale=\"linear\", ylim=(0,1.5))\n",
    "\n",
    "fig.savefig(\"figure6.png\")\n",
    "\n",
    "# ax.set(title=\"Evolution of forecast mass over time for different As \\nLegend: Double gyre A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for f in folders:\n",
    "    name = \"\"\n",
    "    if retrieveNumValueFromFolderName(f, 'rad') != np.inf:\n",
    "        continue\n",
    "    if np.isnan(retrieveNumValueFromFolderName(f, 'meaninit')):\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'obscov') != 0.01:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'ens') != 10:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'eps') != 0.25:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'A') != 0.1:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'devinit') != 0.05:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'v') != 7.3:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'as') != 3:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'meaninit') not in [0.25,0.5,1,2,5]:\n",
    "        continue\n",
    "    for k in ['meaninit']:\n",
    "        name += \"$\\mu$ = \" + str(retrieveNumValueFromFolderName(f, k))\n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    if (df_sim[\"weights_means\"][:] < 10).all():\n",
    "        out[name] = df_sim[\"weights_means\"]\n",
    "\n",
    "df_convergence_weight_meaninits_means = pd.DataFrame(out)\n",
    "df_convergence_weight_meaninits_means['Reference'] = 1\n",
    "df_convergence_weight_meaninits_means = df_convergence_weight_meaninits_means.reindex(sorted(df_convergence_weight_meaninits_means.columns, reverse=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.set_context(\"talk\")\n",
    "ax.set(xscale=\"linear\", ylim=(0,1.5))\n",
    "ax = sns.lineplot(data=df_convergence_weight_meaninits_means, dashes=True, color=\"0.75\", palette=sns.color_palette(n_colors=6, desat=False))\n",
    "ax.set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\")\n",
    "# ax.set(title=\"Evolution of forecast mass over time for different inital masses \\nLegend: Initial total mass relative to reference\")\n",
    "fig.savefig(\"figure3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for f in folders:\n",
    "    name = \"\"\n",
    "    if retrieveNumValueFromFolderName(f, 'rad') != np.inf:\n",
    "        continue\n",
    "    if np.isnan(retrieveNumValueFromFolderName(f, 'meaninit')):\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'obscov') not in [0.01]:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'nbparts') not in [25000]:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'v') != 7.3:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'ens') not in [10]:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'meaninit') != 2:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'A') != 0.1:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'eps') != 0.25:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'devinit') != 0.05:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'obspoints')[0] != (12,4):\n",
    "        continue\n",
    "    for k in ['obspoints']:\n",
    "        name += '$N_{o}' + \" = \" + str(len(retrieveNumValueFromFolderName(f, k))) + \"$ \"\n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    if (df_sim[\"weights_means\"][:] < 5).all():\n",
    "        nbparts = retrieveNumValueFromFolderName(f, 'nbparts')\n",
    "        out[name] = df_sim[\"weights_means\"] * nbparts / 25000\n",
    "\n",
    "df_convergence_weight_No_means = pd.DataFrame(out)\n",
    "df_convergence_weight_No_means['Reference'] = 1\n",
    "df_convergence_weight_No_means = df_convergence_weight_No_means.reindex(sorted(df_convergence_weight_No_means.columns, reverse=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.set_context(\"talk\")\n",
    "ax.set(xscale=\"linear\", ylim=(0.5,1.5))\n",
    "ax = sns.lineplot(data=df_convergence_weight_No_means, dashes=True, color=\"0.75\", palette=sns.color_palette(n_colors=6, desat=False))\n",
    "ax.set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\")\n",
    "# ax.set(title=\"Evolution of forecast mass over time for different inital masses \\nLegend: Initial total mass relative to reference\")\n",
    "# fig.savefig(\"figure7.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = {}\n",
    "\n",
    "for f in folders:\n",
    "    name = \"\"\n",
    "    if retrieveNumValueFromFolderName(f, 'rad') != np.inf:\n",
    "        continue\n",
    "    if np.isnan(retrieveNumValueFromFolderName(f, 'meaninit')):\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'ens') not in [10]:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'eps') != 0.25:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'A') != 0.1:\n",
    "        continue\n",
    "    if retrieveNumValueFromFolderName(f, 'v') not in [6, 6.1]:\n",
    "        continue\n",
    "    for k in ['meaninit', 'obscov', 'obspoints', 'v']:\n",
    "        name += k + \" = \" + str(retrieveNumValueFromFolderName(f, k)) + \" \"\n",
    "    df_sim = pd.read_csv(f + '//log.csv')\n",
    "    n = df_sim.shape[0] if MAX_ITER_COUNT == None else min(MAX_ITER_COUNT, df_sim.shape[0])\n",
    "    if (df_sim[\"weights_means\"][:] < 10).all():\n",
    "        out[name] = df_sim[\"weights_means\"]\n",
    "\n",
    "df_convergence_weight_version_means = pd.DataFrame(out)\n",
    "df_convergence_weight_version_means['Reference'] = 1\n",
    "df_convergence_weight_version_means = df_convergence_weight_version_means.reindex(sorted(df_convergence_weight_version_means.columns, reverse=True), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.set_context(\"talk\")\n",
    "ax.set(xscale=\"linear\", ylim=(0.5,1.2))\n",
    "ax = sns.lineplot(data=df_convergence_weight_version_means, dashes=False, color=\"0.75\")\n",
    "ax.set(xlabel=\"Iteration count\", ylabel=\"Total mass / $M_{ref}$\")\n",
    "# ax.set(title=\"Evolution of forecast mass over time for different inital masses \\nLegend: Initial total mass relative to reference\"\n",
    "# fig.savefig(\"figurex.png\")"
   ]
  },
  {
   "source": [
    "# Generate LateX table"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper = df_lastStats[df_lastStats['v'] == 7.3][df_lastStats['rsd'] == 0]\n",
    "df_paper = df_paper[df_paper['nbparts'] == 25000]\n",
    "df_paper = df_paper[df_paper['A'] ]\n",
    "df_paper['RMSE'] = df_paper['CFRMS'].round(decimals=3)\n",
    "df_paper['FTM'] = df_paper['lastWMean'].round(decimals=3)\n",
    "df_paper['A'] = df_paper['A'].astype(str)\n",
    "df_paper['eps'] = df_paper['eps'].astype(str)\n",
    "df_paper = df_paper[['A', 'eps', 'meaninit', 'devinit', 'nbobspoints', 'obscov', 'FTM', 'RMSE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper['RMSE_NO_DA'] = df_paper.apply(lambda row: computeRMSEWithoutCorrection(row['eps'], row['A'], row['meaninit']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_paper['RMSE_NO_DA'] = df_paper['RMSE_NO_DA'].round(decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_paper.sort_values('FTM', ascending=False).to_latex(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bite12c688a3e8a4484b02a30e603ed49a1",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}